{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variational Quantum Boltzmann Machine - Qiskit Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "\n",
    "# Circuit Imports\n",
    "from qiskit.circuit.library import RealAmplitudes, EfficientSU2\n",
    "from qiskit.circuit import Parameter\n",
    "\n",
    "# Operator Imports\n",
    "from qiskit.aqua.operators import I, Z, StateFn, CircuitStateFn, SummedOp\n",
    "from qiskit.aqua.operators.gradients import NaturalGradient\n",
    "\n",
    "# Additional Imports\n",
    "from qiskit.quantum_info import state_fidelity, partial_trace, Statevector\n",
    "from qiskit.aqua.components.optimizers import SPSA, CG, ADAM, COBYLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gibbs state preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define the system parameters and initialize an Ansatz\n",
    "\n",
    "$\\rho^{Gibbs} = \\frac{e^H/{k_BT}}{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "k_BT = 1\n",
    "\n",
    "# Evolution time\n",
    "t =  1/(2*k_BT)\n",
    "\n",
    "# Define the model Hamiltonian \n",
    "H = SummedOp([0.3 * Z^Z^ I^I, 0.2 * Z^I^ I^I,  0.5 * I^Z^ I^I]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Define the system parameters and initialize an Ansatz\n",
    "\n",
    "$\\rho^{Gibbs} = \\frac{e^H/{k_BT}}{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model ansatz\n",
    "depth = 1\n",
    "entangler_map = [[i+1, i] for i in range(H.num_qubits - 1)]\n",
    "ansatz = EfficientSU2(4, reps=depth, entanglement = entangler_map)\n",
    "qr = ansatz.qregs[0]\n",
    "for i in range(int(len(qr)/2)):\n",
    "    ansatz.cx(qr[i], qr[i+int(len(qr)/2)])\n",
    "    \n",
    "# Initialize the Ansatz parameters\n",
    "param_values_init = np.zeros(2* H.num_qubits * (depth + 1))\n",
    "for j in range(2 * H.num_qubits * depth, int(len(param_values_init) - H.num_qubits - 2)):\n",
    "    param_values_init[int(j)] = np.pi/2.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Initial State\n",
    "\n",
    "The Ansatz $|\\psi\\left(\\omega\\left(\\tau\\right)\\right)\\rangle$ is initialized such that the first two qubits are in a maximally mixed state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters  [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         1.57079633 1.57079633 0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "\n",
      " Circuit       ┌─────────┐┌─────────┐┌───┐┌──────────┐┌─────────┐                       »\n",
      "q_0: ┤ RY(0.0) ├┤ RZ(0.0) ├┤ X ├┤ RY(pi/2) ├┤ RZ(0.0) ├───────────────────────»\n",
      "     ├─────────┤├─────────┤└─┬─┘└──┬───┬───┘├─────────┴┐┌─────────┐           »\n",
      "q_1: ┤ RY(0.0) ├┤ RZ(0.0) ├──■─────┤ X ├────┤ RY(pi/2) ├┤ RZ(0.0) ├───────────»\n",
      "     ├─────────┤├─────────┤        └─┬─┘    └──┬───┬───┘├─────────┤┌─────────┐»\n",
      "q_2: ┤ RY(0.0) ├┤ RZ(0.0) ├──────────■─────────┤ X ├────┤ RY(0.0) ├┤ RZ(0.0) ├»\n",
      "     ├─────────┤├─────────┤                    └─┬─┘    ├─────────┤├─────────┤»\n",
      "q_3: ┤ RY(0.0) ├┤ RZ(0.0) ├──────────────────────■──────┤ RY(0.0) ├┤ RZ(0.0) ├»\n",
      "     └─────────┘└─────────┘                             └─────────┘└─────────┘»\n",
      "«               \n",
      "«q_0: ──■───────\n",
      "«       │       \n",
      "«q_1: ──┼────■──\n",
      "«     ┌─┴─┐  │  \n",
      "«q_2: ┤ X ├──┼──\n",
      "«     └───┘┌─┴─┐\n",
      "«q_3: ─────┤ X ├\n",
      "«          └───┘\n",
      "\n",
      " Full statevector  [0.5+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.5+0.j 0. +0.j 0. +0.j 0. +0.j\n",
      " 0. +0.j 0.5+0.j 0. +0.j 0. +0.j 0. +0.j 0. +0.j 0.5+0.j]\n",
      "\n",
      " Maximally mixed state [[0.25+0.j 0.  +0.j 0.  +0.j 0.  +0.j]\n",
      " [0.  +0.j 0.25+0.j 0.  +0.j 0.  +0.j]\n",
      " [0.  +0.j 0.  +0.j 0.25+0.j 0.  +0.j]\n",
      " [0.  +0.j 0.  +0.j 0.  +0.j 0.25+0.j]]\n"
     ]
    }
   ],
   "source": [
    "print('Initial parameters ', param_values_init)\n",
    "\n",
    "# Initial State\n",
    "\n",
    "print('\\n Circuit ', ansatz.assign_parameters(dict(zip(ansatz.ordered_parameters, param_values_init))))\n",
    "\n",
    "print('\\n Full statevector ', CircuitStateFn(ansatz.assign_parameters \\\n",
    "                                          (dict(zip(ansatz.ordered_parameters, param_values_init)))).eval().primitive.data)\n",
    "\n",
    "print('\\n Maximally mixed state', partial_trace(CircuitStateFn(ansatz.assign_parameters\\\n",
    "                        (dict(zip(ansatz.ordered_parameters, param_values_init)))).eval().primitive.data, [0, 1]).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Let's define the target observable consisting of the Ansatz and the Hamiltonian\n",
    "\n",
    "$$ \\langle \\psi\\left(\\omega\\left(\\tau\\right)\\right)|H|\\psi\\left(\\omega\\left(\\tau\\right)\\right)\\rangle $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Energy expectation value of the initial state  0j\n"
     ]
    }
   ],
   "source": [
    "# Define the Hamiltonian as observable w.r.t. the wavefunction generated by the Ansatz   \n",
    "# Use statevector simulation\n",
    "ansatz_op = CircuitStateFn(ansatz)\n",
    "op = ~StateFn(H) @ ansatz_op\n",
    "\n",
    "print('\\n Energy expectation value of the initial state ', op.assign_parameters(dict(zip(ansatz.ordered_parameters, param_values_init))).eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Target state\n",
    "\n",
    "$\\rho^{target} = \\frac{e^{H\\otimes I}/{k_BT}}{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target state  [[0.14517971+0.j 0.        +0.j 0.        +0.j 0.        +0.j]\n",
      " [0.        +0.j 0.32310338+0.j 0.        +0.j 0.        +0.j]\n",
      " [0.        +0.j 0.        +0.j 0.23936087+0.j 0.        +0.j]\n",
      " [0.        +0.j 0.        +0.j 0.        +0.j 0.29235603+0.j]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the density matrix corresponding to the target Gibbs state\n",
    "h_mat = H.to_matrix()\n",
    "gibbs_target = expm(-h_mat*t) / np.trace(expm(-h_mat*t))\n",
    "gibbs_target = partial_trace(gibbs_target, [0, 1]).data\n",
    "\n",
    "print('Target state ', gibbs_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the parameter propagation rule according to McLachlan's variational principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_gibbs_state_params(op, ansatz, param_values, time_steps):\n",
    "\n",
    "    # Convert the operator that holds the Hamiltonian and ansatz into a NaturalGradient operator \n",
    "    nat_grad = NaturalGradient().convert(op, ansatz.ordered_parameters, method = 'lin_comb', regularization = 'ridge')\n",
    "\n",
    "    # Propagate the Ansatz parameters step by step according to the explicit Euler method\n",
    "    for step in time_steps:\n",
    "        param_dict = dict(zip(ansatz.ordered_parameters, param_values))\n",
    "        nat_grad_result = np.real(nat_grad.assign_parameters(param_dict).eval())\n",
    "#         print('param values',  param_values)\n",
    "#         print('nat_grad_result', nat_grad_result)\n",
    "        param_values = list(np.subtract(param_values, t/num_time_steps * np.real(nat_grad_result)))\n",
    "#         param_values -= t/num_time_steps * nat_grad_result\n",
    "    return param_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the parameter propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameter values [0.3749036942290603, -0.43572349498883567, -0.009030779741659218, -0.006811506369529301, -0.003304803691351454, -0.0024457760857510883, -0.0022871881496703966, -0.0022875325681968386, 1.9648430931471146, 1.702030981046452, -0.009572828153655242, -0.008464544991570882, -0.011185070230071474, -0.011050363556707712, -0.0022894055703115636, -0.0022880456330672794]\n"
     ]
    }
   ],
   "source": [
    "# Define the discretization grid of the time steps\n",
    "num_time_steps = 10\n",
    "time_steps = np.linspace(0, t, num_time_steps)\n",
    "param_values = get_gibbs_state_params(op, ansatz, param_values_init, time_steps)\n",
    "    \n",
    "print('Final parameter values', param_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Check the fidelity between trained and target state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gibbs state  [[ 0.018+0.j  0.   -0.j -0.001+0.j -0.001+0.j]\n",
      " [ 0.   +0.j  0.499+0.j -0.002-0.j -0.004-0.j]\n",
      " [-0.001-0.j -0.002+0.j  0.151+0.j -0.004+0.j]\n",
      " [-0.001-0.j -0.004+0.j -0.004-0.j  0.332+0.j]]\n",
      "Target state  [[0.145+0.j 0.   +0.j 0.   +0.j 0.   +0.j]\n",
      " [0.   +0.j 0.323+0.j 0.   +0.j 0.   +0.j]\n",
      " [0.   +0.j 0.   +0.j 0.239+0.j 0.   +0.j]\n",
      " [0.   +0.j 0.   +0.j 0.   +0.j 0.292+0.j]]\n",
      "Fidelity between trained and target state  0.9098183229613638\n"
     ]
    }
   ],
   "source": [
    "# Compute the density matrix corresponding to the final Gibbs state    \n",
    "gibbs_state = Statevector.from_instruction(ansatz.assign_parameters(dict(zip(ansatz.ordered_parameters, param_values))))\n",
    "gibbs_state = partial_trace(gibbs_state, [0, 1])\n",
    "print('Gibbs state ', np.around(gibbs_state.data, 3))\n",
    "\n",
    "print('Target state ', np.around(gibbs_target.data, 3))\n",
    "\n",
    "# Evaluate the fidelity between the trained and the target state\n",
    "fidelity = state_fidelity(np.around(gibbs_target.data, 3), np.around(gibbs_state.data, 3), validate=False)\n",
    "\n",
    "print('Fidelity between trained and target state ', fidelity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train a generative QBM \n",
    "More explicitly, we train here a fully visible, diagonal, generative QBM using gradient-free optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Initialize a parameterized Hamiltonian and the target PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Parameter('a')    \n",
    "b = Parameter('b')\n",
    "c = Parameter('c')  \n",
    "\n",
    "# Define the model Hamiltonian with parameters\n",
    "H = SummedOp([a * Z^Z^I^I, b * Z^I^ I ^ I, c * I ^ Z^ I ^ I]) \n",
    "\n",
    "# Define the target PDF\n",
    "p_target = [0.5, 0, 0, 0.5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Define the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def loss(H_coeffs):\n",
    "    H_op = H.assign_parameters(dict(zip([a, b, c], np.real(H_coeffs))))\n",
    "    \n",
    "    #Combine the measurement and ansatz operator\n",
    "    op = ~StateFn(H_op) @ ansatz_op\n",
    "    \n",
    "    #Prepare the Gibbs state\n",
    "    param_values = get_gibbs_state_params(op, ansatz, param_values_init, time_steps)\n",
    "    p_qbm = ansatz_op.assign_parameters(dict(zip(ansatz.ordered_parameters, param_values))).eval().primitive\n",
    "    p_qbm = np.diag(partial_trace(p_qbm, [0, 1]).data)\n",
    "    print('Trained probability ', p_qbm)\n",
    "    loss_fn = -np.sum(np.multiply(p_target, np.log(p_qbm)))\n",
    "#     print(loss_fn)\n",
    "    return np.real(loss_fn)\n",
    "\n",
    "optimizer = COBYLA(maxiter = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the QBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained probability  [8.48166349e-02+0.j 5.35282486e-05+0.j 1.16288702e-05+0.j\n",
      " 9.15118208e-01+0.j]\n",
      "Trained probability  [0.11235428+0.j 0.01344755+0.j 0.00452502+0.j 0.86967315+0.j]\n",
      "Trained probability  [5.02006416e-03+0.j 2.48864339e-04+0.j 2.96425811e-03+0.j\n",
      " 9.91766813e-01+0.j]\n",
      "Trained probability  [8.03924477e-03+0.j 1.31406174e-02+0.j 1.52759372e-04+0.j\n",
      " 9.78667379e-01+0.j]\n",
      "Trained probability  [0.91874606+0.j 0.01040262+0.j 0.00111659+0.j 0.06973473+0.j]\n",
      "Trained probability  [0.54836422+0.j 0.02360498+0.j 0.00482062+0.j 0.42321019+0.j]\n",
      "Trained probability  [0.87279533+0.j 0.00468846+0.j 0.00718843+0.j 0.11532778+0.j]\n",
      "Trained probability  [0.49774057+0.j 0.06594721+0.j 0.01316869+0.j 0.42314352+0.j]\n",
      "Trained probability  [6.82181976e-01+0.j 5.84857785e-02+0.j 3.84399848e-04+0.j\n",
      " 2.58947845e-01+0.j]\n",
      "Trained probability  [0.29447541+0.j 0.0190001 +0.j 0.0047767 +0.j 0.68174779+0.j]\n",
      "Trained probability  [0.57574504+0.j 0.03019854+0.j 0.00275329+0.j 0.39130313+0.j]\n",
      "Trained probability  [0.65709287+0.j 0.01444516+0.j 0.00397031+0.j 0.32449166+0.j]\n",
      "Trained probability  [0.48602033+0.j 0.022004  +0.j 0.00487294+0.j 0.48710272+0.j]\n",
      "Trained probability  [0.43505763+0.j 0.02680114+0.j 0.00628718+0.j 0.53185405+0.j]\n",
      "Trained probability  [0.48825569+0.j 0.02013587+0.j 0.00540288+0.j 0.48620556+0.j]\n",
      "Trained probability  [0.48140921+0.j 0.0151559 +0.j 0.00435782+0.j 0.49907708+0.j]\n",
      "Trained probability  [0.42335249+0.j 0.01299307+0.j 0.00445639+0.j 0.55919805+0.j]\n",
      "Trained probability  [0.51208976+0.j 0.01379042+0.j 0.00395333+0.j 0.47016649+0.j]\n",
      "Trained probability  [0.51343566+0.j 0.01440276+0.j 0.00341729+0.j 0.46874429+0.j]\n",
      "Trained probability  [0.50352895+0.j 0.01295802+0.j 0.00384229+0.j 0.47967074+0.j]\n",
      "Trained probability  [0.49690521+0.j 0.01111787+0.j 0.00356452+0.j 0.48841239+0.j]\n",
      "Trained probability  [0.46648977+0.j 0.01041105+0.j 0.00356495+0.j 0.51953422+0.j]\n",
      "Trained probability  [0.51890934+0.j 0.00964596+0.j 0.00335722+0.j 0.46808748+0.j]\n",
      "Trained probability  [0.52604376+0.j 0.00957419+0.j 0.0028158 +0.j 0.46156624+0.j]\n",
      "Trained probability  [0.55052041+0.j 0.00958799+0.j 0.00342637+0.j 0.43646524+0.j]\n",
      "Trained probability  [0.50604582+0.j 0.00919292+0.j 0.00333619+0.j 0.48142506+0.j]\n",
      "Trained probability  [0.49401368+0.j 0.00870804+0.j 0.00331537+0.j 0.49396291+0.j]\n",
      "Trained probability  [0.48916639+0.j 0.00811516+0.j 0.00337197+0.j 0.49934647+0.j]\n",
      "Trained probability  [0.47192821+0.j 0.00810442+0.j 0.00349657+0.j 0.51647079+0.j]\n",
      "Trained probability  [0.49484956+0.j 0.00767229+0.j 0.00309976+0.j 0.4943784 +0.j]\n",
      "Trained probability  [0.5092831 +0.j 0.00726075+0.j 0.00301987+0.j 0.48043628+0.j]\n",
      "Trained probability  [0.50647411+0.j 0.00704634+0.j 0.00293008+0.j 0.48354948+0.j]\n",
      "Trained probability  [0.5041804 +0.j 0.0068504 +0.j 0.00283167+0.j 0.48613753+0.j]\n",
      "Trained probability  [0.50390205+0.j 0.00668355+0.j 0.00271709+0.j 0.48669732+0.j]\n",
      "Trained probability  [0.49967487+0.j 0.00645213+0.j 0.0026946 +0.j 0.4911784 +0.j]\n",
      "Trained probability  [0.49182903+0.j 0.00643177+0.j 0.00267266+0.j 0.49906654+0.j]\n",
      "Trained probability  [0.49387802+0.j 0.0064    +0.j 0.00261383+0.j 0.49710815+0.j]\n",
      "Trained probability  [0.49537906+0.j 0.00613841+0.j 0.00254648+0.j 0.49593605+0.j]\n",
      "Trained probability  [0.49722172+0.j 0.00590857+0.j 0.00246142+0.j 0.4944083 +0.j]\n",
      "Trained probability  [0.49584479+0.j 0.00566937+0.j 0.00241999+0.j 0.49606586+0.j]\n",
      "Trained probability  [0.500215  +0.j 0.00544994+0.j 0.00237656+0.j 0.49195849+0.j]\n",
      "Trained probability  [0.50022026+0.j 0.00525505+0.j 0.00229507+0.j 0.49222961+0.j]\n",
      "Trained probability  [0.49961493+0.j 0.00504463+0.j 0.00223843+0.j 0.493102  +0.j]\n",
      "Trained probability  [0.50014311+0.j 0.00484816+0.j 0.00216975+0.j 0.49283899+0.j]\n",
      "Trained probability  [0.50049756+0.j 0.0046455 +0.j 0.00215409+0.j 0.49270284+0.j]\n",
      "Trained probability  [0.49591602+0.j 0.00449974+0.j 0.00211355+0.j 0.49747069+0.j]\n",
      "Trained probability  [0.49636085+0.j 0.00432312+0.j 0.00204897+0.j 0.49726706+0.j]\n",
      "Trained probability  [0.49581583+0.j 0.00414785+0.j 0.00199641+0.j 0.49803992+0.j]\n",
      "Trained probability  [0.49083899+0.j 0.00400866+0.j 0.00198562+0.j 0.50316673+0.j]\n",
      "Trained probability  [0.49232072+0.j 0.00394996+0.j 0.00189614+0.j 0.50183319+0.j]\n",
      "Trained parameters  [-1.29810568 -0.04292338  0.1362023 ]\n"
     ]
    }
   ],
   "source": [
    "result = optimizer.optimize(3, loss, initial_point = ([-2 , .2, .5]))\n",
    "print('Trained parameters ', result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1-norm between trained and target distributions  0.015359158264474126\n"
     ]
    }
   ],
   "source": [
    "#Construct the Hamiltonian with the final parameterw\n",
    "H_op = H.assign_parameters(dict(zip([a, b, c], [-1.29810568, -0.04292338,  0.1362023])))\n",
    "\n",
    "#Combine the measurement and ansatz operator\n",
    "op = ~StateFn(H_op) @ ansatz_op\n",
    "\n",
    "#Prepare the Gibbs state\n",
    "param_values = get_gibbs_state_params(op, ansatz, param_values_init, time_steps)\n",
    "\n",
    "# Get the sampling probabilities\n",
    "p_qbm = ansatz_op.assign_parameters(dict(zip(ansatz.ordered_parameters, param_values))).eval().primitive\n",
    "p_qbm = np.diag(partial_trace(p_qbm, [0, 1]).data)\n",
    "\n",
    "# Evaluate the l1 norm between the trained and the target state\n",
    "norm = np.linalg.norm(p_target-p_qbm, ord = 1)\n",
    "\n",
    "print('L1-norm between trained and target distributions ', norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_qbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "a = Parameter('a')    \n",
    "b = Parameter('b')\n",
    "c = Parameter('c')  \n",
    "\n",
    "# Define the model Hamiltonian with parameters\n",
    "H = (a * Z^Z + b * Z^I - c * I ^ Z) ^ I ^ I\n",
    "\n",
    "# Define the target PDF\n",
    "p_target = [0.5, 0, 0, 0.5] \n",
    "\n",
    "# Use statevector simulation\n",
    "ansatz_op = CircuitStateFn(qc = ansatz)\n",
    "p_qbm = ansatz_op.assign_parameter(dict(zip(ansatz.ordered_parameters, param_values))).eval()\n",
    "\n",
    "\n",
    "loss = -np.sum(np.multiply(p_target, np.log(p_qbm)))\n",
    "\n",
    "domega_p_qbm = Gradient().convert(op = ansatz_op, params = ansatz.ordered_parameters, method = 'lin_comb')\n",
    "\n",
    "qfi = QFI().convert(op = ansatz_op, params = ansatz.ordered_parameters)\n",
    "from  qiskit.aqua.operator.gradients.gradient.natural_gradient import regularized_sle_solver\n",
    "\n",
    "dH_omega = regularized_sle_solver(qfi * 0.25, dH_C - dH_A*nat_grad_result, regularization = 'ridge')\n",
    "\n",
    "dH_p_qbm = domega_p_qbm * dH_omega\n",
    "\n",
    "dH_loss = -np.tensordot(np.divide(dH_p_qbm, p_qbm), [p_target], axes=1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "QiskitDevenv",
   "language": "python",
   "name": "qiskitdevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
