{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantum generative adversarial networks for learning and loading random distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction\n",
    "Given $k$-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data's underlying random distribution and to load it directly into a quantum state:\n",
    "\n",
    "$$ \\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle $$\n",
    "\n",
    "where $p_{\\theta}^{j}$ describe the occurrence probabilities of the basis states $\\big| j\\rangle$. \n",
    "\n",
    "The aim of the qGAN training is to generate a state $\\big| g_{\\theta}\\rangle$ where $p_{\\theta}^{j}$, for $j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}$, describe a probability distribution that is close to the distribution underlying the training data $X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}$.\n",
    "\n",
    "For further details please refer to <a href=\"https://arxiv.org/abs/1904.00043\">Quantum Generative Adversarial Networks for Learning and Loading Random Distributions. Zoufal, Lucchi, Woerner. 2019.</a>\n",
    "\n",
    "How to use a trained qGAN in an application, i.e., pricing of financial derivatives, is illustrated here:\n",
    "<a href=\"../finance/machine_learning/qgan_option_pricing.ipynb\">qGAN Option Pricing</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "from torch import optim\n",
    "from qiskit import QuantumRegister, QuantumCircuit\n",
    "from qiskit.aqua.components.optimizers import ADAM\n",
    "from qiskit.aqua.components.uncertainty_models import UniformDistribution, UnivariateVariationalDistribution \n",
    "from qiskit.circuit.library import TwoLocal\n",
    "\n",
    "from qiskit.aqua.algorithms import QGAN\n",
    "from qiskit.aqua.components.neural_networks.quantum_generator import QuantumGenerator\n",
    "from qiskit.aqua.components.neural_networks import PyTorchDiscriminator\n",
    "\n",
    "from qiskit.aqua import aqua_globals, QuantumInstance\n",
    "from qiskit.aqua.components.initial_states import Custom\n",
    "\n",
    "from qiskit import BasicAer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data\n",
    "First, we need to load the $k$-dimensional training data samples (here k=1). <br/>\n",
    "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number training data samples\n",
    "N = 1000 \n",
    "\n",
    "# Load data samples from a distribution with mean=1 and standard deviation=1\n",
    "mu = 1\n",
    "sigma = 1\n",
    "\n",
    "def load_bm_data(N=10000, sig_a=1., mean_a=0.5, sig_b=0.5, mean_b=3.5):\n",
    "    # Draw N samples from a bimodal (2 Gaussians) distribution.\n",
    "    data = [sig_a*np.random.randn(N) + mean_a, sig_b*np.random.randn(N) + mean_b]\n",
    "    return np.array(data).flatten()\n",
    "\n",
    "# real_data = np.random.lognormal(mean = mu, sigma=sigma, size=N)\n",
    "real_data = load_bm_data(N=N)\n",
    "\n",
    "# Set the data resolution\n",
    "# Set upper and lower data values as list of k min/max data values [[min_0,max_0],...,[min_k-1,max_k-1]]\n",
    "bounds = np.array([0.,3.]) \n",
    "# Set number of qubits per data dimension as list of k qubit values[#q_0,...,#q_k-1]\n",
    "num_qubits = [2]\n",
    "k = len(num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the qGAN\n",
    "The qGAN consists of a quantum generator $G_{\\theta}$, a variational quantum circuit, and a classical discriminator $D_{\\phi}$, a neural network. <br/>\n",
    "To implement the quantum generator, we choose a depth-$1$ variational form that implements $R_Y$ rotations and $CZ$ gates which takes a uniform distribution as an input state. Notably, for $k>1$ the generator's parameters must be chosen carefully. For example, the circuit depth should be $>1$ because higher circuit depths enable the representation of more complex structures.<br/>\n",
    "The classical discriminator is given by a $3$-layer neural network that applies linear transformations, leaky ReLU functions in the hidden layers and a sigmoid function in the output layer. Notably, the neural network is implemented with PyTorch. Please refer to https://pytorch.org/get-started/locally/ for PyTorch installation instructions.<br/>\n",
    "Here, both networks are updated with the ADAM optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of training epochs\n",
    "# Note: The algorithm's runtime can be shortened by reducing the number of training epochs.\n",
    "num_epochs = 3000\n",
    "# Batch size\n",
    "batch_size = 100\n",
    "\n",
    " # Initialize qGAN\n",
    "qgan = QGAN(real_data, bounds, num_qubits, batch_size, num_epochs, snapshot_dir=None)\n",
    "qgan.seed = 1\n",
    "# Set quantum instance to run the quantum generator\n",
    "quantum_instance = QuantumInstance(backend=BasicAer.get_backend('statevector_simulator'))\n",
    "\n",
    "# Set entanglement\n",
    "entanglement = 'sca'\n",
    "\n",
    "\n",
    "# Set an initial state for the generator circuit\n",
    "init_dist = UniformDistribution(sum(num_qubits), low=bounds[0], high=bounds[1])\n",
    "q = QuantumRegister(sum(num_qubits), name='q')\n",
    "qc = QuantumCircuit(q)\n",
    "init_dist.build(qc, q)\n",
    "init_distribution = Custom(num_qubits=sum(num_qubits), circuit=qc)\n",
    "var_form = TwoLocal(int(np.sum(num_qubits)), 'ry', 'cz', entanglement=entanglement,\n",
    "                    reps=3, initial_state=init_distribution)\n",
    "\n",
    "print(var_form)\n",
    "\n",
    "# Set generator's initial parameters\n",
    "init_params = np.random.rand(var_form.num_parameters_settable) * 2 * np.pi\n",
    "# Set generator circuit\n",
    "g_circuit = UnivariateVariationalDistribution(int(sum(num_qubits)), var_form, init_params,\n",
    "                                              low=bounds[0], high=bounds[1])\n",
    "# Set quantum generator\n",
    "qgan.set_generator(generator_circuit=g_circuit)\n",
    "# Set classical discriminator neural network\n",
    "discriminator = PyTorchDiscriminator(len(num_qubits))\n",
    "qgan.set_discriminator(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run qGAN\n",
    "qgan.run(quantum_instance)\n",
    "\n",
    "# Runtime\n",
    "end = time.time()\n",
    "print('qGAN training runtime: ', (end - start)/60., ' min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Progress & Outcome\n",
    "Now, we plot the evolution of the generator's and the discriminator's loss functions during the training as well as the progress in the relative entropy between the trained and the target distribution.\n",
    "<br/> Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot progress w.r.t the generator's and the discriminator's loss function\n",
    "t_steps = np.arange(num_epochs)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.title(\"Progress in the loss function\")\n",
    "plt.plot(t_steps, qgan.g_loss, label = \"Generator loss function\", color = 'mediumvioletred', linewidth = 2)\n",
    "plt.plot(t_steps, qgan.d_loss, label = \"Discriminator loss function\", color = 'rebeccapurple', linewidth = 2)\n",
    "plt.grid()\n",
    "plt.legend(loc = 'best')\n",
    "plt.xlabel('time steps')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot progress w.r.t relative entropy\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.title(\"Relative Entropy \")\n",
    "plt.plot(np.linspace(0, num_epochs, len(qgan.rel_entr)), qgan.rel_entr, color ='mediumblue', lw=4, ls=':')\n",
    "plt.grid()\n",
    "plt.xlabel('time steps')\n",
    "plt.ylabel('relative entropy')\n",
    "plt.show()\n",
    "\n",
    "#Plot the PDF of the resulting distribution against the target distribution, i.e. log-normal\n",
    "log_normal = np.random.lognormal(mean=1, sigma=1, size=100000)\n",
    "log_normal = np.round(log_normal)\n",
    "log_normal = log_normal[log_normal <= bounds[1]]\n",
    "temp = []\n",
    "for i in range(int(bounds[1]+1)):\n",
    "    temp += [np.sum(log_normal==i)]\n",
    "log_normal = np.array(temp / sum(temp))\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.title(\"CDF\")\n",
    "samples_g, prob_g = qgan.generator.get_output(qgan.quantum_instance, shots=10000)\n",
    "samples_g = np.array(samples_g)\n",
    "samples_g = samples_g.flatten()\n",
    "num_bins = len(prob_g)\n",
    "plt.bar(samples_g,  np.cumsum(prob_g), color='royalblue', width= 0.8, label='simulation')\n",
    "plt.plot( np.cumsum(log_normal),'-o', label='log-normal', color='deepskyblue', linewidth=4, markersize=12)\n",
    "plt.xticks(np.arange(min(samples_g), max(samples_g)+1, 1.0))\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('p(x)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "QiskitDevenv",
   "language": "python",
   "name": "qiskitdevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
